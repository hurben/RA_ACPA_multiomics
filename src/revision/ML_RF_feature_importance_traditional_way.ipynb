{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9046c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909d50e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(base_dir, group_comparison, selector_name=\"none\", selector=None, k=None):\n",
    "    \"\"\"\n",
    "    selector_name: \"none\" or \"kbest\"\n",
    "    selector: sklearn selector object (fit on train, transform both)\n",
    "    k: number of features (for logging only)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for fold in range(1, 6):\n",
    "        train_file = os.path.join(base_dir, f\"{fold}fold/multiplex.train.tsv\")\n",
    "        test_file  = os.path.join(base_dir, f\"{fold}fold/multiplex.test.tsv\")\n",
    "\n",
    "        # --- Load ---\n",
    "        train_df = pd.read_csv(train_file, sep=\"\\t\", index_col=0)\n",
    "        test_df  = pd.read_csv(test_file,  sep=\"\\t\", index_col=0)\n",
    "\n",
    "        #negVSpos\n",
    "        if group_comparison == \"cVSneg\":\n",
    "            train_selected_cols = train_df.columns[(train_df.loc[\"acpa\"] == 2) | (train_df.loc[\"acpa\"] == 0)]\n",
    "            test_selected_cols = test_df.columns[(test_df.loc[\"acpa\"] == 2) | (test_df.loc[\"acpa\"] == 0)]\n",
    "\n",
    "        if group_comparison == \"cVSpos\":\n",
    "            train_selected_cols = train_df.columns[(train_df.loc[\"acpa\"] == 1) | (train_df.loc[\"acpa\"] == 0)]\n",
    "            test_selected_cols = test_df.columns[(test_df.loc[\"acpa\"] == 1) | (test_df.loc[\"acpa\"] == 0)]\n",
    "\n",
    "        if group_comparison == \"cVSra\":\n",
    "            train_selected_cols = train_df.columns[(train_df.loc[\"acpa\"] == 2) | (train_df.loc[\"acpa\"] == 1) | (train_df.loc[\"acpa\"] == 0)]\n",
    "            test_selected_cols = test_df.columns[(test_df.loc[\"acpa\"] == 2)| (test_df.loc[\"acpa\"] == 1) | (test_df.loc[\"acpa\"] == 0)]\n",
    "\n",
    "        # Transform ACPA values: convert 2 to 1 for binary classification (1 or 0)\n",
    "        train_df.loc[\"acpa\"] = train_df.loc[\"acpa\"].replace(2, 1)\n",
    "        test_df.loc[\"acpa\"] = test_df.loc[\"acpa\"].replace(2, 1)\n",
    "\n",
    "        train_df = train_df[train_selected_cols]\n",
    "        test_df = test_df[test_selected_cols]\n",
    "\n",
    "        # Drop rows with index 'acpa_neg', 'acpa_pos', and 'control'\n",
    "        train_df = train_df.drop(['acpa_neg', 'acpa_pos', 'control'])\n",
    "        test_df  = test_df.drop(['acpa_neg', 'acpa_pos', 'control'])\n",
    "\n",
    "        y_train = train_df.iloc[0]\n",
    "        y_test  = test_df.iloc[0]\n",
    "\n",
    "        X_train_df = train_df.iloc[1:].T.copy()\n",
    "        X_test_df  = test_df.iloc[1:].T.copy()\n",
    "\n",
    "        feature_names = np.array(X_train_df.columns)\n",
    "\n",
    "        # --- Feature selection (fit on train, apply to both) ---\n",
    "        if selector is not None:\n",
    "            sel = selector \n",
    "            sel.fit(X_train_df, y_train)\n",
    "            X_train = sel.transform(X_train_df)\n",
    "            X_test  = sel.transform(X_test_df)\n",
    "\n",
    "            # map importances back to selected feature names\n",
    "            selected_mask = sel.get_support()\n",
    "            selected_features = feature_names[selected_mask]\n",
    "            \n",
    "        else:\n",
    "            X_train = X_train_df\n",
    "            X_test  = X_test_df\n",
    "            selected_features = feature_names\n",
    "\n",
    "        # Save dataframe with selected features for tracking\n",
    "        selected_features_df = pd.DataFrame(X_train, columns=selected_features)\n",
    "        selected_features_df.to_csv(\n",
    "            os.path.join(\"/Users/m221138/RA_ACPA_multiomics/analysis/machine_learning_r1.1/5fold/enet_2condition_alternative/\", f\"{fold}fold_selected_features_{selector_name}.tsv\"),\n",
    "            index=False,\n",
    "            sep=\"\\t\"\n",
    "        )\n",
    "        # --- Model ---\n",
    "        clf = RandomForestClassifier(random_state=seed)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # --- Metrics & importances (mapped to selected feature names) ---\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        importances = pd.Series(clf.feature_importances_, index=selected_features)\\\n",
    "                        .sort_values(ascending=False)\n",
    "\n",
    "        results.append({\n",
    "            \"fold\": fold,\n",
    "            \"accuracy\": acc,\n",
    "            \"report\": classification_report(y_test, y_pred, zero_division=0),\n",
    "            \"importances\": importances\n",
    "        })\n",
    "\n",
    "    # --- Summary ---\n",
    "    accuracies = [r[\"accuracy\"] for r in results]\n",
    "    avg_acc = statistics.mean(accuracies)\n",
    "    std_acc = statistics.stdev(accuracies) if len(accuracies) > 1 else 0.0\n",
    "\n",
    "    print(f\"\\n=== {selector_name.upper()} RESULTS{f' (k={k})' if k else ''} ===\")\n",
    "    for r in results:\n",
    "        print(f\"Fold {r['fold']} accuracy: {r['accuracy']:.4f}\")\n",
    "    print(f\"Average accuracy: {avg_acc:.6f} ± {std_acc:.6f}\")\n",
    "\n",
    "    # Return results if you want to aggregate importances outside\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "317849ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"//Users/m221138/RA_ACPA_multiomics/analysis/5fold_data_r1.1/network_construction_enet\"\n",
    "seed = 225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "106a267c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NONE RESULTS ===\n",
      "Fold 1 accuracy: 0.5000\n",
      "Fold 2 accuracy: 0.6875\n",
      "Fold 3 accuracy: 0.5625\n",
      "Fold 4 accuracy: 0.6250\n",
      "Fold 5 accuracy: 0.8125\n",
      "Average accuracy: 0.637500 ± 0.120221\n",
      "['pyruvate' 'sphingosine 1-phosphate' 'X-12462' 'X-19438'\n",
      " 'p_METRNL_21705-33' 'p_CNTN5_3299-29' 'p_RGMB_3331-8' 'p_PGAM1_3896-5'\n",
      " 'p_NAMPT_5011-11' 'p_COL15A1_8974-172']\n",
      "['pyruvate' '1-oleoyl-2-docosahexaenoyl-GPC (18:1/22:6)*'\n",
      " '3,5-dichloro-2,6-dihydroxybenzoic acid' 'X-12462' 'X-15245' 'X-19438'\n",
      " 'X-24295' 'p_BLVRB_17148-7' 'p_NAMPT_5011-11' 'p_CTRB2_5648-28']\n",
      "['ornithine' 'lactate' 'pyruvate' 'sphingosine 1-phosphate'\n",
      " '3,5-dichloro-2,6-dihydroxybenzoic acid' 'X-12104' 'X-12462' 'X-19438'\n",
      " 'X-24295' 'p_NAMPT_5011-11']\n",
      "['pyruvate' '1-oleoyl-2-docosahexaenoyl-GPC (18:1/22:6)*' 'X-12462'\n",
      " 'X-15245' 'X-19438' 'p_TNFRSF17_2665-26' 'p_CNTN5_3299-29'\n",
      " 'p_RGMB_3331-8' 'p_CHRDL1_3362-61' 'p_NAMPT_5011-11']\n",
      "['pyruvate' 'sarcosine' 'cys-gly, oxidized' 'sphingosine 1-phosphate'\n",
      " '3,5-dichloro-2,6-dihydroxybenzoic acid' 'X-12462' 'X-23276'\n",
      " 'p_PGAM2_15524-30' 'p_PGAM1_3896-5' 'p_NAMPT_5011-11']\n",
      "\n",
      "=== KBEST_ANOVA RESULTS (k=10) ===\n",
      "Fold 1 accuracy: 0.6875\n",
      "Fold 2 accuracy: 0.8125\n",
      "Fold 3 accuracy: 0.8125\n",
      "Fold 4 accuracy: 0.8125\n",
      "Fold 5 accuracy: 0.8750\n",
      "Average accuracy: 0.800000 ± 0.068465\n"
     ]
    }
   ],
   "source": [
    "# -------- Run A) No feature selection --------\n",
    "_ = run_experiment(base_dir, \"cVSneg\", selector_name=\"none\", selector=None)\n",
    "\n",
    "# -------- Run B) SelectKBest (ANOVA) --------\n",
    "k = 10  # <- change this as you like (e.g., 10, 30, 50, 90)\n",
    "_ = run_experiment(base_dir, \"cVSneg\",\n",
    "    selector_name=\"kbest_anova\",\n",
    "    selector=SelectKBest(score_func=f_classif, k=k),\n",
    "    k=k\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157672be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09393282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
