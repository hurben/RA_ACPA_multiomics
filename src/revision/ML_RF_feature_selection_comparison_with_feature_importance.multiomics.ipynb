{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef96d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectFpr, mutual_info_classif\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "909d50e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_line(log_file, text=\"\"):\n",
    "    \"\"\"Append one line to a text file (auto-creates).\"\"\"\n",
    "    with open(log_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(text + \"\\n\")\n",
    "\n",
    "def run_experiment(base_dir, group_comparison, random_seed, log_file, selector_name=\"none\", selector=None):\n",
    "\n",
    "    \"\"\"\n",
    "    selector_name: \"none\" or \"kbest\"\n",
    "    selector: sklearn selector object (fit on train, transform both)\n",
    "    k: number of features (for logging only)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for fold in range(1, 6):\n",
    "        train_file = os.path.join(base_dir, f\"{fold}fold/multiplex.train.tsv\")\n",
    "        test_file  = os.path.join(base_dir, f\"{fold}fold/multiplex.test.tsv\")\n",
    "\n",
    "        # --- Load ---\n",
    "        train_df = pd.read_csv(train_file, sep=\"\\t\", index_col=0)\n",
    "        test_df  = pd.read_csv(test_file,  sep=\"\\t\", index_col=0)\n",
    "\n",
    "        # group filters\n",
    "        if group_comparison == \"cVSneg\":\n",
    "            train_selected_cols = train_df.columns[(train_df.loc[\"acpa\"] == 2) | (train_df.loc[\"acpa\"] == 0)]\n",
    "            test_selected_cols  = test_df.columns[(test_df.loc[\"acpa\"]  == 2) | (test_df.loc[\"acpa\"]  == 0)]\n",
    "        if group_comparison == \"cVSpos\":\n",
    "            train_selected_cols = train_df.columns[(train_df.loc[\"acpa\"] == 1) | (train_df.loc[\"acpa\"] == 0)]\n",
    "            test_selected_cols  = test_df.columns[(test_df.loc[\"acpa\"]  == 1) | (test_df.loc[\"acpa\"]  == 0)]\n",
    "        if group_comparison == \"cVSra\":\n",
    "            train_selected_cols = train_df.columns[(train_df.loc[\"acpa\"].isin([0,1,2]))]\n",
    "            test_selected_cols  = test_df.columns[(test_df.loc[\"acpa\"].isin([0,1,2]))]\n",
    "\n",
    "        # Convert 2 -> 1 for binary\n",
    "        train_df.loc[\"acpa\"] = train_df.loc[\"acpa\"].replace(2, 1)\n",
    "        test_df.loc[\"acpa\"]  = test_df.loc[\"acpa\"].replace(2, 1)\n",
    "\n",
    "        # apply column selection\n",
    "        train_df = train_df[train_selected_cols]\n",
    "        test_df  = test_df[test_selected_cols]\n",
    "\n",
    "        # Drop label helper rows\n",
    "        for lab in [\"acpa_neg\", \"acpa_pos\", \"control\"]:\n",
    "            if lab in train_df.index:\n",
    "                train_df = train_df.drop(lab)\n",
    "            if lab in test_df.index:\n",
    "                test_df = test_df.drop(lab)\n",
    "\n",
    "        # y is first row; ensure integer 0/1\n",
    "        y_train = train_df.iloc[0].astype(int)\n",
    "        y_test  = test_df.iloc[0].astype(int)\n",
    "\n",
    "        # X are remaining rows (samples x features)\n",
    "        X_train_df = train_df.iloc[1:].T.copy()\n",
    "        X_test_df  = test_df.iloc[1:].T.copy()\n",
    "\n",
    "        feature_names = np.array(X_train_df.columns)\n",
    "\n",
    "        # # --- Feature selection (fit on train, apply to both) ---\n",
    "        # if selector is not None:\n",
    "        #     sel = selector\n",
    "        #     sel.fit(X_train_df, y_train)\n",
    "        #     X_train = sel.transform(X_train_df)\n",
    "        #     X_test  = sel.transform(X_test_df)\n",
    "        #     selected_mask = sel.get_support()\n",
    "        #     selected_features = feature_names[selected_mask]  #because feature selection, get subset\n",
    "        # else:\n",
    "        #     X_train = X_train_df.values\n",
    "        #     X_test  = X_test_df.values\n",
    "        #     selected_features = feature_names #because no feature selection, just proceed\n",
    "\n",
    "                        # --- feature selection ---\n",
    "        if selector_name == \"mutual_info_classif\":\n",
    "            mi_func = partial(mutual_info_classif, random_state=random_seed)\n",
    "            sel = SelectKBest(score_func=mi_func)   # fresh selector per fold\n",
    "        elif selector is not None:\n",
    "            # clone() is safest if you passed a fitted sklearn object\n",
    "            from sklearn.base import clone\n",
    "            sel = clone(selector)\n",
    "        else:\n",
    "            sel = None\n",
    "\n",
    "        if sel is not None:\n",
    "            X_train = sel.fit_transform(X_train_df, y_train)\n",
    "            X_test  = sel.transform(X_test_df)\n",
    "            selected_features = X_train_df.columns[sel.get_support()]\n",
    "        else:\n",
    "            X_train, X_test = X_train_df.values, X_test_df.values\n",
    "            selected_features = X_train_df.columns\n",
    "\n",
    "        # Save selected train matrix for tracking (optional)\n",
    "        selected_features_df = pd.DataFrame(X_train, columns=selected_features)\n",
    "        out_dir = \"/Users/m221138/RA_ACPA_multiomics/analysis/machine_learning_r1.1/5fold/enet_2condition_alternative\"\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        selected_features_df.to_csv(\n",
    "            os.path.join(out_dir, f\"{fold}fold_selected_features_{selector_name}.tsv\"),\n",
    "            index=False, sep=\"\\t\"\n",
    "        )\n",
    "\n",
    "        # --- Model ---\n",
    "        clf = RandomForestClassifier(random_state=random_seed)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # --- Metrics ---\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # AUC: needs at least one pos and one neg in y_test\n",
    "        if len(np.unique(y_test)) == 2:\n",
    "            # RandomForest supports predict_proba\n",
    "            y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "            auc = roc_auc_score(y_test, y_prob)\n",
    "        else:\n",
    "            auc = np.nan  # undefined if only one class present in this fold's test\n",
    "\n",
    "        # Importances mapped to selected features\n",
    "        importances = pd.Series(clf.feature_importances_, index=selected_features).sort_values(ascending=False)\n",
    "\n",
    "        results.append({\n",
    "            \"fold\": fold,\n",
    "            \"accuracy\": acc,\n",
    "            \"auc\": auc,\n",
    "            \"report\": classification_report(y_test, y_pred, zero_division=0),\n",
    "            \"importances\": importances\n",
    "        })\n",
    "\n",
    "    # --- Summary ---\n",
    "    accuracies = [r[\"accuracy\"] for r in results]\n",
    "    aucs = [r[\"auc\"] for r in results]  # may include NaNs\n",
    "\n",
    "    avg_acc = statistics.mean(accuracies)\n",
    "    std_acc = statistics.stdev(accuracies) if len(accuracies) > 1 else 0.0\n",
    "\n",
    "    # Use nan-robust stats for AUC\n",
    "    auc_arr = np.array(aucs, dtype=float)\n",
    "    avg_auc = float(np.nanmean(auc_arr)) if np.any(~np.isnan(auc_arr)) else np.nan\n",
    "    std_auc = float(np.nanstd(auc_arr)) if np.any(~np.isnan(auc_arr)) else np.nan\n",
    "\n",
    "    print(f\"\\n=== {selector_name.upper()} ===\")\n",
    "    for r in results:\n",
    "        auc_str = \"nan\" if np.isnan(r[\"auc\"]) else f\"{r['auc']:.4f}\"\n",
    "        \n",
    "    print(f\"Average accuracy: {avg_acc:.6f} ± {std_acc:.6f}\")\n",
    "    print(f\"Average AUC     : {avg_auc if np.isnan(avg_auc) else f'{avg_auc:.6f}'} ± {std_auc if np.isnan(std_auc) else f'{std_auc:.6f}'}\")\n",
    "\n",
    "    # also append summary to the same log (still appending)\n",
    "    if log_file:\n",
    "        write_line(log_file, f\"{group_comparison}\\t{selector_name}\\t{avg_auc:.6f}\\t{std_auc:.6f}\\t{avg_acc:.6f}\\t{std_acc:.6f}\")\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b0baf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = \"/Users/m221138/RA_ACPA_multiomics/analysis/machine_learning_r1.1/5fold/enet_2condition_alternative/results.multiomics.log.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "106a267c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACPA-negative\n",
      "\n",
      "=== NONE ===\n",
      "Average accuracy: 0.637500 ± 0.120221\n",
      "Average AUC     : 0.765625 ± 0.155074\n",
      "\n",
      "=== KBEST_ANOVA ===\n",
      "Average accuracy: 0.800000 ± 0.068465\n",
      "Average AUC     : 0.884375 ± 0.050967\n",
      "\n",
      "=== FPR_ANOVA_Q0.05 ===\n",
      "Average accuracy: 0.762500 ± 0.189572\n",
      "Average AUC     : 0.834375 ± 0.183379\n",
      "\n",
      "=== MUTUAL_INFO_CLASSIF ===\n",
      "Average accuracy: 0.787500 ± 0.104583\n",
      "Average AUC     : 0.879687 ± 0.057111\n"
     ]
    }
   ],
   "source": [
    "#multi-omics\n",
    "base_dir = \"//Users/m221138/RA_ACPA_multiomics/analysis/5fold_data_r1.1/network_construction_enet\"\n",
    "random_seed = 225\n",
    "\n",
    "print (\"ACPA-negative\")\n",
    "\n",
    "# -------- Run A) No feature selection --------\n",
    "_ = run_experiment(base_dir, \"cVSneg\", random_seed, log_file, selector_name=\"none\", selector=None)\n",
    "\n",
    "# -------- Run B) SelectKBest (ANOVA) --------\n",
    "# k = 10  # <- change this as you like (e.g., 10, 30, 50, 90)\n",
    "seed = 225\n",
    "_ = run_experiment(base_dir, \"cVSneg\", random_seed, log_file,\n",
    "    selector_name=\"kbest_anova\",\n",
    "    selector=SelectKBest(score_func=f_classif)\n",
    ")\n",
    "\n",
    "# -------- Run B) SelectKBest (ANOVA) --------\n",
    "_ = run_experiment(base_dir, \"cVSneg\", random_seed, log_file,\n",
    "    selector_name=\"fpr_anova_q0.05\",\n",
    "    selector=SelectFpr(score_func=f_classif, alpha=0.05)\n",
    ")\n",
    "\n",
    "# # -------- Run B) SelectKBest (ANOVA) --------\n",
    "# _ = run_experiment(base_dir, \"cVSneg\", random_seed, log_file,\n",
    "#     selector_name=\"anova k=90\",\n",
    "#     selector=SelectKBest(score_func=f_classif, k=90)\n",
    "# )\n",
    "\n",
    "_ = run_experiment(base_dir, \"cVSneg\", random_seed, log_file,\n",
    "    selector_name=\"mutual_info_classif\",\n",
    "    selector=SelectKBest(score_func=mutual_info_classif)\n",
    ")\n",
    "\n",
    "# _ = run_experiment(base_dir, \"cVSneg\", random_seed, log_file,\n",
    "#     selector_name=\"mutual_info_classif k=90\",\n",
    "#     selector=SelectKBest(score_func=mutual_info_classif, k=90)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "157672be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACPA-positive\n",
      "\n",
      "=== NONE ===\n",
      "Average accuracy: 0.637500 ± 0.120221\n",
      "Average AUC     : 0.742188 ± 0.114394\n",
      "\n",
      "=== KBEST_ANOVA ===\n",
      "Average accuracy: 0.750000 ± 0.044194\n",
      "Average AUC     : 0.882812 ± 0.064234\n",
      "\n",
      "=== FPR_ANOVA_Q0.05 ===\n",
      "Average accuracy: 0.687500 ± 0.088388\n",
      "Average AUC     : 0.740625 ± 0.087193\n",
      "\n",
      "=== MUTUAL_INFO_CLASSIF ===\n",
      "Average accuracy: 0.825000 ± 0.120221\n",
      "Average AUC     : 0.923438 ± 0.043188\n"
     ]
    }
   ],
   "source": [
    "random_seed = 18\n",
    "print (\"ACPA-positive\")\n",
    "\n",
    "# -------- Run A) No feature selection --------\n",
    "_ = run_experiment(base_dir, \"cVSpos\", random_seed, log_file, selector_name=\"none\", selector=None)\n",
    "\n",
    "\n",
    "_ = run_experiment(base_dir, \"cVSpos\", random_seed, log_file,\n",
    "    selector_name=\"kbest_anova\",\n",
    "    selector=SelectKBest(score_func=f_classif)\n",
    ")\n",
    "\n",
    "# -------- Run B) SelectKBest (ANOVA) --------\n",
    "_ = run_experiment(base_dir, \"cVSpos\", random_seed, log_file,\n",
    "    selector_name=\"fpr_anova_q0.05\",\n",
    "    selector=SelectFpr(score_func=f_classif, alpha=0.05)\n",
    ")\n",
    "\n",
    "# # -------- Run B) SelectKBest (ANOVA) --------\n",
    "# _ = run_experiment(base_dir, \"cVSpos\", random_seed, log_file,\n",
    "#     selector_name=\"anova k=70\",\n",
    "#     selector=SelectKBest(score_func=f_classif, k=70)\n",
    "# )\n",
    "\n",
    "_ = run_experiment(base_dir, \"cVSpos\", random_seed, log_file,\n",
    "    selector_name=\"mutual_info_classif\",\n",
    "    selector=SelectKBest(score_func=mutual_info_classif)\n",
    ")\n",
    "\n",
    "# _ = run_experiment(base_dir, \"cVSpos\", random_seed, log_file,\n",
    "#     selector_name=\"mutual_info_classif k=70\",\n",
    "#     selector=SelectKBest(score_func=mutual_info_classif, k=70)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09393282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RA\n",
      "\n",
      "=== NONE ===\n",
      "Average accuracy: 0.708333 ± 0.121478\n",
      "Average AUC     : 0.725781 ± 0.141175\n",
      "\n",
      "=== KBEST_ANOVA ===\n",
      "Average accuracy: 0.758333 ± 0.099478\n",
      "Average AUC     : 0.870313 ± 0.066768\n",
      "\n",
      "=== FPR_ANOVA_Q0.05 ===\n",
      "Average accuracy: 0.741667 ± 0.068465\n",
      "Average AUC     : 0.826562 ± 0.094709\n",
      "\n",
      "=== MUTUAL_INFO_CLASSIF ===\n",
      "Average accuracy: 0.858333 ± 0.095924\n",
      "Average AUC     : 0.896094 ± 0.053708\n"
     ]
    }
   ],
   "source": [
    "random_seed = 174\n",
    "print (\"RA\")\n",
    "# -------- Run A) No feature selection --------\n",
    "_ = run_experiment(base_dir, \"cVSra\", random_seed, log_file, selector_name=\"none\", selector=None)\n",
    "\n",
    "\n",
    "_ = run_experiment(base_dir, \"cVSra\", random_seed, log_file,\n",
    "    selector_name=\"kbest_anova\",\n",
    "    selector=SelectKBest(score_func=f_classif)\n",
    ")\n",
    "\n",
    "# -------- Run B) SelectKBest (ANOVA) --------\n",
    "_ = run_experiment(base_dir, \"cVSra\", random_seed, log_file,\n",
    "    selector_name=\"fpr_anova_q0.05\",\n",
    "    selector=SelectFpr(score_func=f_classif, alpha=0.05)\n",
    ")\n",
    "\n",
    "# # -------- Run B) SelectKBest (ANOVA) --------\n",
    "# _ = run_experiment(base_dir, \"cVSra\", random_seed, log_file,\n",
    "#     selector_name=\"anova k=70\",\n",
    "#     selector=SelectKBest(score_func=f_classif, k=70)\n",
    "# )\n",
    "\n",
    "_ = run_experiment(base_dir, \"cVSra\", random_seed, log_file,\n",
    "    selector_name=\"mutual_info_classif\",\n",
    "    selector=SelectKBest(score_func=mutual_info_classif)\n",
    ")\n",
    "\n",
    "# _ = run_experiment(base_dir, \"cVSra\", random_seed, log_file,\n",
    "#     selector_name=\"mutual_info_classif k=70\",\n",
    "#     selector=SelectKBest(score_func=mutual_info_classif, k=70)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad463f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491ab3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
