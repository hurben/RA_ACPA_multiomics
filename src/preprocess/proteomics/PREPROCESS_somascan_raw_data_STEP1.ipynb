{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecological-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESS_somascan_raw_data_STEP1\n",
    "#\n",
    "#Preprocess for the proteomics data. Mainly, only considering Human proteins.\n",
    "#Thus, we will remove: \n",
    "#Non-human protein, Spuriomer, Spurimer, HCE, Non-Biotin, Non-Cleavable, etc.\n",
    "#\n",
    "#In order to address the duplicates (However, different isoform),\n",
    "#Feature = [PROTEIN SYMBOL]_[BARCODE]\n",
    "#\n",
    "#Intended inputs: somascan_data_parse_ready.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "generic-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "included-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_from_anml_data(data_file):\n",
    "    data_open = open(data_file,'r')\n",
    "    data_readlines = data_open.readlines()\n",
    "    \n",
    "    sample_ID_list = []\n",
    "    protein_list =[]\n",
    "    data_dict = {}\n",
    "       \n",
    "    temp_seq_ID_list = data_readlines[0].split('\\t')\n",
    "    temp_protein_list = data_readlines[7].split('\\t')\n",
    "    temp_species_list = data_readlines[8].split('\\t')\n",
    "    target_type_list = data_readlines[10].split('\\t')\n",
    "    \n",
    "    \n",
    "    #make protein_list without mouse proteins\n",
    "    for i in range(len(temp_species_list)):\n",
    "        protein_name = temp_protein_list[i]\n",
    "        species_type = temp_species_list[i]\n",
    "        target_type = target_type_list[i]\n",
    "\n",
    "        if species_type == \"Human\":            \n",
    "            if target_type == \"Protein\":\n",
    "                if protein_name != \"None\":  \n",
    "                    seq_ID = temp_seq_ID_list[i]\n",
    "                    protein_name_with_seqID = '%s_%s' % (protein_name, seq_ID)\n",
    "                    protein_list.append(protein_name_with_seqID)\n",
    "\n",
    "    #make dict[sampleid, protein] = value\n",
    "    for i in range(21, len(data_readlines)):\n",
    "        read = data_readlines[i]\n",
    "        read = read.replace('\\n','')\n",
    "        token = read.split('\\t')\n",
    "        \n",
    "        sample_ID = token[0]\n",
    "        sample_ID_list.append(sample_ID)\n",
    "        sample_specific_protein_dict_list = []\n",
    "\n",
    "        for j in range(1, len(token)):\n",
    "            \n",
    "            protein_symbol = temp_protein_list[j]\n",
    "            species_type = temp_species_list[j]\n",
    "            target_type = target_type_list[j]\n",
    "            seq_ID = temp_seq_ID_list[j]\n",
    "            \n",
    "            value = token[j]\n",
    "            \n",
    "            if species_type == \"Human\": #do only human proteins\n",
    "                if protein_symbol != \"None\":\n",
    "                    if target_type == \"Protein\":\n",
    "                        if protein_symbol not in sample_specific_protein_dict_list:    \n",
    "                            protein_name_with_seqID = '%s_%s' % (protein_symbol, seq_ID)\n",
    "                            data_dict[sample_ID, protein_name_with_seqID] = value\n",
    "                            sample_specific_protein_dict_list.append(protein_name_with_seqID)\n",
    "                    \n",
    "    return sample_ID_list, protein_list, data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "challenging-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_output_from_dict(sample_ID_list, protein_list, data_dict, output_dir):\n",
    "    output_txt = open(output_dir,'w')\n",
    "    \n",
    "    #write header\n",
    "    output_txt.write('sample_ID')\n",
    "    for protein_symbol in protein_list:\n",
    "        output_txt.write('\\t%s' % protein_symbol)\n",
    "    output_txt.write('\\n')\n",
    "    \n",
    "    #write main\n",
    "    for sample_ID in sample_ID_list:\n",
    "        output_txt.write(sample_ID)\n",
    "        for protein_symbol in protein_list:\n",
    "            value = data_dict[sample_ID, protein_symbol]\n",
    "            output_txt.write('\\t%s' % value)\n",
    "        output_txt.write('\\n')\n",
    "    \n",
    "    \n",
    "    output_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "radical-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../../../raw_data/RA_somascan/MAYO-216978_v4.1_EDTAPlasma_20210905/somascan_data_parse_ready.tsv\"\n",
    "output_file = '../../../preprocessed_data/proteomics/somascan_anml.tsv'\n",
    "\n",
    "sample_ID_list, protein_list, data_dict = parse_from_anml_data(data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "manual-healing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_output_from_dict(sample_ID_list, protein_list, data_dict, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "reverse-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transpose_data\n",
    "data_df = pd.read_csv(output_file, sep=\"\\t\", index_col=0)\n",
    "data_df = data_df.T\n",
    "data_df.to_csv('../../../preprocessed_data/proteomics/somascan_anml.T.tsv', sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
